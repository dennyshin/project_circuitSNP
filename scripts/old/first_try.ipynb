{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with M00001\n",
    "\n",
    "First, I start by bringing in \"M00001.combo.bed\".\n",
    "This file contains all of the open chromatin regions for the motif M00001 for all tissue types.\n",
    "\n",
    "Let's start by bringing the file in and seeing what it looks like first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr1\\t74497\\t74510\\tM00001\\t6.2881446601367\\t- \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifM00001 = []\n",
    "with open(\"data/CENTIPEDEdata/motif.combo/M00001.combo.bed\") as f:\n",
    "    for line in f:\n",
    "        motifM00001.append(line)\n",
    "\n",
    "motifM00001[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings each line as a long string\n",
    "\n",
    "Instead, I would like to seperate out each column. I do this by adding the split() method. I have seen people use strip() and then a split() but I have yet to see any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1', '74497', '74510', 'M00001', '6.2881446601367', '-']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifM00001 = []\n",
    "with open(\"data/CENTIPEDEdata/motif.combo/M00001.combo.bed\") as f:\n",
    "    for line in f:\n",
    "        motifM00001.append(line.split())\n",
    "\n",
    "motifM00001[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just grab the chr1 data for time saving.\n",
    "\n",
    "Also, I really only want columns 2 and 3: the start and end positions for the motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['249099975', '249099988'], ['249100896', '249100909'], ['249108148', '249108161'], ['249209440', '249209453'], ['249236293', '249236306']]\n",
      "65491\n",
      "5182\n"
     ]
    }
   ],
   "source": [
    "motifM00001_chr1 = []\n",
    "i = 0\n",
    "while motifM00001[i][0] == \"chr1\":\n",
    "    motifM00001_chr1.append(motifM00001[i][1:3]) # just grab index 1 and 2\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(motifM00001_chr1[-5:])\n",
    "print(len(motifM00001))\n",
    "print(len(motifM00001_chr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13: 5182}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_length_dict = {}\n",
    "for region in motifM00001_chr1:\n",
    "    region_length = int(region[1]) - int(region[0])\n",
    "    \n",
    "    if region_length in region_length_dict:\n",
    "        region_length_dict[region_length] += 1\n",
    "    else:\n",
    "        region_length_dict[region_length] = 1\n",
    "        \n",
    "region_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see all region lengths are 13 because of the motif length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, I would like to convert the elements into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifM00001_chr1 = [list(map(int,i)) for i in motifM00001_chr1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249099975, 249099988],\n",
       " [249100896, 249100909],\n",
       " [249108148, 249108161],\n",
       " [249209440, 249209453],\n",
       " [249236293, 249236306]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifM00001_chr1[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrowPeak file\n",
    "I do the same for the narrowPeak file, which contains all open regions for the LCL tissue type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17753\n"
     ]
    }
   ],
   "source": [
    "open_LCL_chr1 = []\n",
    "with open(\"data/CENTIPEDEdata/wgEncodeAwgDnaseUwdukeGm12878UniPk.narrowPeak\") as f:\n",
    "    for line in f:\n",
    "        if line.split()[0] == \"chr1\":\n",
    "            open_LCL_chr1.append(line.split()[1:3])\n",
    "\n",
    "open_LCL_chr1 = [list(map(int,i)) for i in open_LCL_chr1]\n",
    "print(len(open_LCL_chr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249200725, 249200875],\n",
       " [249200920, 249201070],\n",
       " [249218985, 249219135],\n",
       " [249219525, 249219675],\n",
       " [249220645, 249220795]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_LCL_chr1[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list \"narrowPeak_LCL_chr1\" will be the building block for the \"output\" vector. Any regions that overlap with the motifM00001_chr1 list will be \"1\" in the input matrix for the column motifM00001_chr1. This is all probably be a lot easier if we use pandas instead now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{150: 17693, 250: 20, 270: 12, 290: 20, 230: 6, 210: 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_length_dict = {}\n",
    "for region in open_LCL_chr1:\n",
    "    region_length = int(region[1]) - int(region[0])\n",
    "    \n",
    "    if region_length in region_length_dict:\n",
    "        region_length_dict[region_length] += 1\n",
    "    else:\n",
    "        region_length_dict[region_length] = 1\n",
    "        \n",
    "region_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the region length is mostly 150 but not all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is not helpful EXCEPT for learning about np.insert"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## working on our output vector\n",
    "\n",
    "Let's start by working with the narrowPeak data (our \"output\").\n",
    "I try a np.array()\n",
    "\n",
    "import numpy as np\n",
    "output = np.array(open_LCL_chr1)\n",
    "print(output[-5:]) # last 5\n",
    "\n",
    "Perfect. Now, we should add a third column containing all \"1\". \"1\" represents that this region of chromatin is open. An good example to follow is: ![np.insert_example](imgs/np.insert_example.png)\n",
    "\n",
    "The example is here is adding column (axis=1) of \"5\"s into column index \"1\"\n",
    "\n",
    "NOTE: np.insert DOES NOT occur in-place.\n",
    "\n",
    "output = np.insert(output, 2, 1, axis=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working with ClusteredV3.bed file\n",
    "\n",
    "This is the file where all open chromatin regions for ALL tissues are stored. The tissues are identified by the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173415\n"
     ]
    }
   ],
   "source": [
    "open_all_tissues_chr1 = []\n",
    "with open(\"data/CENTIPEDEdata/wgEncodeRegDnaseClusteredV3.bed\") as f:\n",
    "    for line in f:\n",
    "        if line.split()[0] == \"chr1\":\n",
    "            open_all_tissues_chr1.append(line.split()[1:3])\n",
    "            \n",
    "open_all_tissues_chr1 = [list(map(int,i)) for i in open_all_tissues_chr1]\n",
    "print(len(open_all_tissues_chr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249222400, 249222575],\n",
       " [249222960, 249223130],\n",
       " [249223340, 249223490],\n",
       " [249223825, 249223975],\n",
       " [249239705, 249239930]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_all_tissues_chr1[-5:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "region_length_dict = {}\n",
    "for region in open_all_tissues_chr1:\n",
    "    region_length = int(region[1]) - int(region[0])\n",
    "    \n",
    "    if region_length in region_length_dict:\n",
    "        region_length_dict[region_length] += 1\n",
    "    else:\n",
    "        region_length_dict[region_length] = 1\n",
    "        \n",
    "region_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT TO NOTE HERE IS THAT THE REGION LENGTH CHANGES A LOT. press \"O\" to see. I have left the cell as \"raw\" because I don't want it to run all the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making output vector\n",
    "\n",
    "We have all open regions for the LCL tissue. Now we would like some closed regions. We use the open regions in ALL tissues as candidates for closed regions for the LCL tissue. In other words we want to create output instances with \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind myself what they look like first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249200725, 249200875],\n",
       " [249200920, 249201070],\n",
       " [249218985, 249219135],\n",
       " [249219525, 249219675],\n",
       " [249220645, 249220795]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_LCL_chr1[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249222400, 249222575],\n",
       " [249222960, 249223130],\n",
       " [249223340, 249223490],\n",
       " [249223825, 249223975],\n",
       " [249239705, 249239930]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_all_tissues_chr1[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open_LCL_chr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open_all_tissues_chr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is unhelpful. I converted it into raw code cells."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's start by initialising our output vector using the open_all_tissues locations.\n",
    "\n",
    "RECALL: np.insert() does not happen inplace\n",
    "\n",
    "output = np.insert(open_all_tissues_chr1, 2, 0, axis=1)\n",
    "print(output[0:5])\n",
    "print(len(output))\n",
    "\n",
    "The next step would be turn these locations to \"1\" if they overlap with regions in the open_LCL array. At the same time I need to add in regions that exist in the open_LCL array but do not exist in open_all_tissues array (I doubt this will happen often). \n",
    "\n",
    "The quickest way to do this would be sift through both \"all tissues\" and \"LCL\" arrays alongside each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is old code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chromosomes = list(openALL.keys())[:-2] #remove sex chromosomes\n",
    "output = dict.fromkeys(chromosomes)\n",
    "\n",
    "for chrm in chromosomes:\n",
    "        \n",
    "    i=0\n",
    "    regionlist = []\n",
    "    for region in openLCL[chrm]:\n",
    "        opregion = [region[0], region[1], 1]\n",
    "        \n",
    "        # | ALL1 | ALL2 | LCL1 |   while no overlap\n",
    "        while openALL[chrm][i][1] < opregion[0]: # ALL_end is smaller than LCL_start\n",
    "            # add in closed region\n",
    "            # [start, end, closed/open]\n",
    "            clregion = [openALL[chrm][i][0], openALL[chrm][i][1], 0]\n",
    "            regionlist.append(clregion)\n",
    "            i += 1\n",
    "            \n",
    "        # now, we must be at an overlap or past it\n",
    "        \n",
    "        # | ALL1 | LCL1 | ALL2 |   ALL_region is part LCL. no overlap\n",
    "        if openALL[chrm][i][0] > opregion[1]: # ALL_start is bigger than LCL_end\n",
    "            # insert open region\n",
    "            regionlist.append(opregion)\n",
    "        \n",
    "        # | ALL1 LCL1 | ALL2    overlap exists\n",
    "        else:\n",
    "            # insert open region\n",
    "            regionlist.append(opregion)\n",
    "            \n",
    "            # | ALL1 LCL1 ALL2 ALL3 | ALL4 |   skip until overlap ends\n",
    "            try:\n",
    "                while openALL[chrm][i][0] <= opregion[1]:\n",
    "                    i += 1\n",
    "            except:\n",
    "                # this means ALL has run out during an overlap\n",
    "                # there may still be regions left in LCL\n",
    "                pass\n",
    "                \n",
    "    # tail end\n",
    "    \n",
    "    \n",
    "    output[chrm] = regionlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead, do:\n",
    "\n",
    "#### BEWARE: IF THE LAST REGION IN 'OPEN_LCL' IS PAST 'OPEN_ALL' THEN WE WOULD HAVE AN OUT OF BOUNDS ERROR. ALSO, THE LAST FEW ENTRIES OF 'OPEN_ALL' HAVE BEEN ADDED BUT IN A BANDAID WAY... NEED TO FIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "i = 0\n",
    "for region in open_LCL_chr1:\n",
    "    \n",
    "    # while no overlap\n",
    "    while open_all_tissues_chr1[i][1] < region[0]:\n",
    "        output.append([open_all_tissues_chr1[i][0], open_all_tissues_chr1[i][1], 0])\n",
    "        i += 1\n",
    "    \n",
    "    # now we must be at an overlap or already past 'region'\n",
    "    \n",
    "    # no overlap\n",
    "    if open_all_tissues_chr1[i][0] > region[1]:\n",
    "        # insert 'region'\n",
    "        output.append([region[0], region[1], 1])\n",
    "        \n",
    "    else:\n",
    "        # i MUST be an overlap now \n",
    "\n",
    "        # insert 'region'\n",
    "        output.append([region[0], region[1], 1])\n",
    "        \n",
    "        # don't insert all_tissue regions until the overlap ends\n",
    "        while (open_all_tissues_chr1[i][0] < region[1]):\n",
    "            i += 1\n",
    "            \n",
    "# ENTRIES THAT HAVE NOT BEEN ADDED BUT SHOULD BE\n",
    "for row in open_all_tissues_chr1[i:]:\n",
    "    output.append([row[0], row[1], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176129"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    10100,     10330,         0],\n",
       "       [    10345,     10590,         0],\n",
       "       [    16100,     16315,         0],\n",
       "       ...,\n",
       "       [249223340, 249223490,         0],\n",
       "       [249223825, 249223975,         0],\n",
       "       [249239705, 249239930,         0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17753"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(output, axis=0)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that all open_LCL regions have been successfully added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10079944583868"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17753/176122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "around 10 percent of the output vector is classified as open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final vector should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.delete(output, [0,1], axis=1)\n",
    "np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input data\n",
    "\n",
    "This brings us back to our M00001.bed file. Remember: this contains binding locations for motif M00001 in ALL tissues.\n",
    "\n",
    "Our final goal is: ![](imgs/data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[249099975, 249099988],\n",
       " [249100896, 249100909],\n",
       " [249108148, 249108161],\n",
       " [249209440, 249209453],\n",
       " [249236293, 249236306]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifM00001_chr1[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    10100,     10330],\n",
       "       [    10345,     10590],\n",
       "       [    16100,     16315],\n",
       "       ...,\n",
       "       [249223340, 249223490],\n",
       "       [249223825, 249223975],\n",
       "       [249239705, 249239930]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = np.delete(output, 2, axis=1)\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_col = []\n",
    "i=0\n",
    "for region in regions:\n",
    "    if i > len(motifM00001_chr1):\n",
    "        break\n",
    "    \n",
    "    # if no overlap\n",
    "    if region[1] < motifM00001_chr1[i][0]:\n",
    "        motif_col.append(0)\n",
    "    else:\n",
    "        # no overlap\n",
    "        if region[0] > motifM00001_chr1[i][1]:\n",
    "            motif_col.append(0)\n",
    "            i += 1 # region is past the motif[i], move forward\n",
    "        \n",
    "        # must be overlap\n",
    "        else:\n",
    "            motif_col.append(1)\n",
    "            # don't move forward as the next region might also be overlap\n",
    "            \n",
    "np.sum(motif_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems to be quite sparse. might be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple motif files\n",
    "\n",
    "Now the challenge is getting many motif.bed files an putting them together. Let's try using os and keep all the motif files in one place to access them as I go instead of making a new array that carries all motif arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5182\n",
      "[[74497, 74510], [104986, 104999], [131373, 131386], [132173, 132186], [172225, 172238]]\n",
      "632\n",
      "[[11401, 11417], [852989, 853005], [855168, 855184], [868745, 868761], [876582, 876598]]\n",
      "1246\n",
      "[[1199051, 1199062], [1943092, 1943103], [2044095, 2044106], [2240050, 2240061], [2281759, 2281770]]\n",
      "101\n",
      "[[6830517, 6830534], [8610228, 8610245], [10347606, 10347623], [14883795, 14883812], [14964135, 14964152]]\n",
      "1725\n",
      "[[855947, 855963], [958589, 958605], [1005655, 1005671], [1026158, 1026174], [1079608, 1079624]]\n"
     ]
    }
   ],
   "source": [
    "path = \"data/CENTIPEDEdata/motif.combo\"\n",
    "for motiffile in os.listdir(path):\n",
    "    motif_combo = []\n",
    "    with open(os.path.join(path, motiffile)) as f:\n",
    "        for line in f:\n",
    "            if line.split()[0] == \"chr1\":\n",
    "                motif_combo.append(line.split()[1:3])\n",
    "    \n",
    "    motif_combo = [list(map(int,i)) for i in motif_combo]\n",
    "    print(len(motif_combo))\n",
    "    print(motif_combo[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay we can very easily bring motif files in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176129\n",
      "176129\n",
      "176129\n",
      "176129\n",
      "176129\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "path = \"data/CENTIPEDEdata/motif.combo\"\n",
    "for motiffile in os.listdir(path):\n",
    "    motif_combo = []\n",
    "    with open(os.path.join(path, motiffile)) as f:\n",
    "        for line in f:\n",
    "            if line.split()[0] == \"chr1\":\n",
    "                motif_combo.append(line.split()[1:3])\n",
    "    \n",
    "    motif_combo = [list(map(int,i)) for i in motif_combo]\n",
    "\n",
    "    motif_col = []\n",
    "    i=0\n",
    "    for region in regions:\n",
    "        if i >= len(motif_combo):\n",
    "            motif_col.append(0)\n",
    "        else:\n",
    "            # if no overlap\n",
    "            if region[1] < motif_combo[i][0]:\n",
    "                motif_col.append(0)\n",
    "            else:\n",
    "                # no overlap\n",
    "                if region[0] > motif_combo[i][1]:\n",
    "                    motif_col.append(0)\n",
    "                    i += 1 # region is past the motif[i], move forward\n",
    "        \n",
    "                # must be overlap\n",
    "                else:\n",
    "                    motif_col.append(1)\n",
    "                    # don't move forward as the next region might also be overlap\n",
    "    \n",
    "    print(len(motif_col))\n",
    "    training_data.append(motif_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176129, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1804,  407,  165,   33,  907])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, we have something we can work with. The next step would be to do this for ALL motif files for ALL chromosomes as well and not just chr1. The attributes pos0 and pos1 in the files \"motif.combo\" are relative to the chromosome which may pose a challenge later. But for now, I think I can test to see if this format will work in a neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using a multilayer perceptron\n",
    "\n",
    "Here, I use tensorflow and keras to build a simple neural net. I would expect it to perform pretty bad I think because of our sparseness and the fact that I haven't used everything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "176129/176129 [==============================] - 23s 132us/sample - loss: 0.3291\n",
      "Epoch 2/3\n",
      "176129/176129 [==============================] - 22s 125us/sample - loss: 0.3271\n",
      "Epoch 3/3\n",
      "176129/176129 [==============================] - 23s 131us/sample - loss: 0.3269\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  768       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  258       \n",
      "=================================================================\n",
      "Total params: 17,538\n",
      "Trainable params: 17,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metris=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results aren't anything spectacular but as long as I know that this data preprocessing works on tensorflow, I am happy... for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
